# Data Management

## Clinical Data Management 

### What 

Clinical Data Management (**CDM**) is the collection, cleaning, and
management of subject data in compliance with regulatory standards
(Krishnankutty\_2012). It is a critical component of clinical research.

### Why

The quality of the data generated by the clinical trial will determine
the soundness of scientific conclusions formed on the basis of analysis.

### How

Data collection and management procedures should be based on sound
statistical principles and compliant with the study protocol and
regulations. CDM protocol should address key project prerequisites
regarding the data collection, storage, protection, retention, and
reporting. Potential problems and solutions proposed solutions should be
reviewed in detail.

The International Conference On Harmonisation (ICH) Guideline E6(R2)
recommends that sponsors of clinical trials “implement systems to manage
quality throughout the design, conduct, recording, evaluation,
reporting, and archiving of clinical trials”… Sponsors should focus on
the “human subject protection and reliability of trial results”… To
warrant the quality of management “the methods selected to assure and
control the quality of the trial need to be proportionate to the risks
inherent in the trial and the importance of the information collected”
(E6\_R2: 5).

The NIH Intramural Research Program Guidelines section on Clinical
Informatics, Data Management, and Protocol Tracking rationale and
standard states:

> *“Collecting clinical data is a complex task that must be integrated
> into the medical practices of the institution. To monitor the study's
> progress and patient safety, data collection is best done as data are
> generated. Data management organized and supported at the institute
> level is more efficient and reliable than that left to the individual
> investigator. There are often unforeseen uses for the kinds of
> information gathered in the conduct of a clinical trial, and a central
> database, with appropriate archiving, assures that this information
> remains the legacy of the institute” *
>
> *Each institute sponsoring clinical research should develop a central
> clinical investigations database that maintains all data specified to
> be collected in the clinical study (either intervention or natural
> history). The clinical research information system being continually
> developed by the Clinical Center interfaces with and supports each
> institute's clinical research needs. A confederated database will
> enable information exchange, enabling access to and sharing of
> clinical and research information among all institutes. The institutes
> require data-management infrastructures to maintain their central data
> registries, to enhance existing databases, to provide eligibility
> checklists, to record patient randomization and entry into their
> protocols, to provide report generation, data warehousing, and data
> entry forms, and to monitor data collection.” (NIH\_standars\_CR)*
>
> The NIA **Clinical Research Study Investigator’s Toolbox** provides
> guidance with specific reference to clinical trials in aging, and in
> particular useful tips for data management. Investigators pursuing or
> conducting federally funded projects should make use of this resource
> (NIA-Guide MOP).

## CLINICAL Data Management definition and procedures

### What

The clinical data management procedures define the methods and dependent
activities in which the clinical data is collected and managed. The
procedures content should include the methods used to assign and
structure participant’s identifiers (ID), the location of the ID logs,
the types of data collection instruments used, a description of how the
data is captured/completed, reviewed, cleaned, and subsequently
stored/archived.

### Why

Data management procedures that are compliant with the trial’s protocol,
good clinical practice (GCP), regulatory requirements, and undergo
regular process audits assures the quality of data necessary to execute
the planned analysis.

### How

The data management procedures are often incorporated as a subsection
within the Manual of Operations (MOO) or Standard Operating Procedures
(SOP). These are executed by project personnel whose portfolio of work
includes data management, and who have appropriate professional training
and credentials in data science broadly defined. IFAR encourages all
investigators and managers to author a MOO or SOP in order to document
the project operations including the data management activities
(IFAR\_sensitive\_data\_security). As noted above, the NIA toolbox
provides general guidance and specific requirements for clinical trials
conducted in the field of aging. Harvard Catalyst has a detailed
planning checklist that can assist researchers describe the data for
protection, IRB submission, and regulatory compliance
(Harvard\_Catalyst: 5).

Extensive and diverse guidance and examples in other fields are also
available online. Some well-executed examples are featured the National
Institute of Dental and Craniofacial Research (NIDCR) and Boston
Children’s Hospital (BCH) Clinical Research Center websites.

#### Systems for data collection and management

Clinical trials may use paper-based or electronic data capture, with
most studies today using the latter. An electronic data capture
(**EDC**) system will be designed to facilitate data collection, often
using web-based technology. A Clinical Data Management Systems
(**CDMS**) comprises the software tools for data maintenance, quality
assurance and reporting. EDC and CDMS may be combined under a single
informatics environment.

ICH guideline E6(R2) recommends that the informatics environment allows
for both data changes (edits) and detailed trail of audits, data, and
editorial information. It also recommends maintaining an SOP for using
these systems and a security system that prevents unauthorized access to
the data (E6\_R2: 5.5).

When describing the data collection system in applications or protocols,
data management personnel should define

-   **The system specifications:** the version number, security system,
    audit trail, data entry access, the annotated case report forms
    (CFR), data validation, system failure mitigation plan, and
    electronic signature features.

-   **User acceptance testing:** the proper function of the system. This
    includes the customized functions, validation checks, the proper
    assignment of site and/or participant identifications numbers, the
    cross confirmation of time to events variable delivery, confirmation
    of data completion, the proper functionality of electronic (e.g.
    e-mail) alerts, as well as the proper function of role assignments,
    data exports/imports, and system reports.

    Detail concerning specific aspects of procedures governing, and
    design of, EDC and CDMS are provided in the sections below.

##### EDC/CDM systems available at IFAR 

[See Appendix I](#systems-available-at-ifar)

#### Data entry procedures

These outline rules for valid data capture. They include the method for
determining that a specific form has been completed, for data cleaning
and quality assurance, storage procedures, and validation checks
designed to ensure that the data capture system operates accurately,
reliably, and consistently. With EDC, the designers of the structure may
impose rules to maintain data and study quality, ranging from the simple
(disallowing, for instance, data falsely labeled with future dates or
biological values incompatible with life) to the more complex (for
instance, implementation of automated checks of inclusion and exclusion
criteria so that ineligible individuals are not enrolled as
participants.

#### Data Security Procedures

Procedures for maintenance of data security – incorporating both
prevention of deletion and prevention of theft – should follow and
expand upon the Data Safety Monitoring Plan (**DSMP**) of the study
protocol. Details on protocol development are provided in the Essential
Documents module.

These procedures should delineate pertinent risks as well as the plan
for prevention of theft or loss, including identification of the
individuals responsible for maintaining and routinely confirming data
security.

### Data cleaning and quality control procedures

These describe the programmed and/or built-in procedures of the EDC
system and CDMS ensuring data validity. Again, automated procedures
(e.g. restriction of allowable values to those that match variable
definitions) may be employed.

#### Data import and exports Procedures

These detail the frequency and methods that are to be used for the
loading of data generated outside the EDC system (for instance as
measured by a third party laboratory that provides data in a flat file
external to the main trial database). Security and preservation of data
quality must be accounted for here.

#### Case Report Forms (CRF)

CRF are the ‘source’ documents – which may be electronic forms - for
recording the protocol-required information to be reported to the
trial’s sponsor on each trial subject.

Paper or electronic documents should be consistent with the source
documents (NIH\_protocol\_template). Investigator must warrant that the
case reports be accurate, complete and legible.\
\
Edits and corrections are to be documented by study personnel with
initials and dates, and be available for audits. The corrections should
not obscure, however, the original data entry such as the audit trail
for either written or electronic data corrections.

At IFAR, the design, analysis, and preparation of the interim and final
clinical trial reports should be done with the guidance of the Research
Informatics and Biostatistics cores as appropriate.

## Monitoring Of study participants 

Participant monitoring is a critical task for trial personnel. The CDMS should support and facilitate this task. Some exemplary functions are described below.

### Screening/Recruitment 


The EDC and CDMS should reinforce the inclusion/exclusion criteria such
that only eligible participants are enrolled.

### Randomization/Blinding procedures

The EDC should facilitate assignment of participants to treatments and
control regimes in a transparent and error-free manner, while
facilitating maintenance of blinding of study personnel as appropriate.
See Experimental design and Statistical Considerations module.

### Cessation of Intervention

The CDMS should provide for notation and monitoring of cessation of
intervention or other trial procedures as indicated by safety
monitoring. Reason for and duration of cessation should be provided,
along with other details Note that this is distinct from withdrawal, as
described above.

### Withdrawals

The CDMS should facilitate the recording of participant withdrawals from
the trial. It should capture the reasons for withdrawal, relevant dates
and other details. It should also facilitate any additional contact with
participants and recording of data relevant to said contacts.

#### Tracking 

The CDMS should facilitate tracking of participants’ enrollment and
progress through the trial consistent with NIH and ICH guidance and with
the reporting paradigm laid out in the Consolidated Standards of
Reporting Trials (**CONSORT**) Statement. CONSORT is a set of
recommendations for reporting the information for randomized trials
including its design, methods, results, and conclusions (Consort). It
comprises a 25-item checklist and flow diagram providing guidance for
study enrollment, retention, and monitoring as well as derivation of
analytic data sets and other data structures.

Study flow diagram

## Reporting

A basic function of the CDMS is reporting of data and metadata relevant
to trial monitoring. Prior to the trial startup the CDM should outline
and describe the list of anticipated study reports. Some considerations
are:

### Safety 

Safety reports should comply with the applicable regulatory
requirement(s) and with the ICH Guidance for Clinical Safety Data
Management (FDA\_CDER\_CBER: 5.17.2). The parties that must receive the
safety reports include all concerned investigator(s)/institutions(s),
the IRB(s)/IEC(s) where required, and regulatory authorities. See Human
Subjects and Essential Documents modules for detail.

#### Adverse events and Serious Adverse Events. 

The CDMS should facilitate reporting of AEs and SAEs consistent with the
study protocol and regulatory requirements (ICH\_E2A). Consideration
should be given to coding of event expectedness, severity and other
relevant qualifications. See Human Subjects and Essential Documents
modules.

### Screening and Enrollment

The EDC and CDMS should be constructed to facilitate regular reporting
of study progress, and specifically screening, enrollment and
participant visit tracking. A reasonable model for said reports is
contained in the DSMB reporting templates provided as part of the NIA
Toolbox
(https://www.nia.nih.gov/research/dgcg/clinical-research-study-investigators-toolbox/startup).

### Data Quality and Completeness

The EDC and CDSM should be structured to facilitate production of data
quality reporting to insure data accuracy, protocol compliance and
adherence to regulatory requirements.

### Progress and Final Reports

Most federally funded projects require yearly progress and final project
reports. State usually done by the PI and grants administrator as they
require scientific and administrative progress. Again, data management
systems should be structured to interact with statistical software and
reporting to facilitate production of these reports.

### Additional Reports

Project-specific reporting is par for the course in any clinical trial,
and will reflect specific complexities of each design. Complex
interventions, cluster designs, and numerous other features will
necessitate redesign of standard reports or construction of new ones.
The EDC and CDMS should be structured to permit easy access to study
data and metadata for authoring of said reports within the CDMS or
parallel technology (e.g. statistical analysis software).

## Trial Documents and Data Retention

### Retention of Trial Documents. 

Source data should be attributable, legible, contemporaneous, original,
accurate, and complete. Changes to source data should be traceable,
should not obscure the original entry and should be explained if
necessary (e.g., via an audit trail).

The ICH E6 guidance (FDA\_CDER\_CBER) recommends that trial documents be
kept by the investigator/institution as specified in Essential Documents
for the Conduct of a Clinical Trial and as required by the applicable
regulatory requirement(s). See Essential Documents module.

### Data Use Agreements (DUA)

SEE Data Use Agreements in the Human Subjects and Regulatory module
(Also, IFAR\_DUA, IFAR\_sensitive\_data\_sharing).

## Special considerations for older subjects

Section 164.514(a) of the Health Insurance Portability and
Accountability Act of 1996 (HIPAA) Privacy Rule provides the standard
for de-identification of protected health information, including that of
older subjects. Under this standard, health information is not
individually identifiable if it does not identify an individual and if
the covered entity has no reasonable basis to believe it can be used to
identify an individual. For older adults over 89 years of age, states
that “all elements of dates (including year) indicative of such age,
except that such ages and elements may be aggregated into a single
category of age 90 or older” (HHS\_hipaa).

As noted above, the NIA Toolbox is an excellent resource for guidance of
specific relevance to federal research in aging.

## APPENDIX I

### NETWORK RESOURCES

At IFAR servers and network resources are accessible to approved staff
only. The list of IFAR preapproved network resources includes:

-   IFAR file servers (e.g. IFAR NAS)

-   Application servers (e.g. REDCap, SharePoint, Accellion)

-   Database servers (e.g. MySQL, SQL Server)

-   Application Security and User Federation

-   IFAR Extranet and User Repository (LDAP)

According to IFAR’s sensitive data security policy projects are
encouraged to maintain a dedicated network share on IFAR or HSL
controlled file servers to ensure secure isolation of data and
materials. Investigators must also follow HSL/IFAR procedures to request
employee access to network resources (see
IFAR\_sensitive\_data\_security).

### SYSTEMS AVAILABLE AT IFAR

#### Electronic Data Capture (EDC)

**Research Electronic Data Capture (REDCap)** is a web application for
building and managing online surveys and databases via secure web
technologies. Each individual project in RedCap is provided a separate
workspace and the data is stored in a MySQL relational database on the
private corporate network behind several firewalls and located within
the HSL data center. The system provides features like audit trails for
tracking data entries and user activity, calendars for scheduling
events, branching logic, file uploading and calculated fields (REDCap).

**Open Clinica** is an open source clinical trial software for EDC and
CDM. The software is used to create project databases, develop eCRFs,
create validation check, schedule events, capture eCRF data from study
sites, monitor and manage the clinical data.

### Data Analytics

**STATA** is a statistical software package used for data analysis, data
management, graphics, simulations and custom programming for multiple
types of data (Stata). The package is available for Windows, OS, X, and
Linux. Its file format permits the exchange of data sets between users
of different operating systems (iu\_kb).

**Statistical Analysis System (SAS)** is a software package used to
enter, retrieve, and manage data. It can also retrieve data for
different operating systems to perform advance statistical and
mathematical analyses, graphics and reporting (sas).

**Statistical Package for the Social Sciences (SPSS) or IMB SPSS
Statistics** is a software used for statistical analysis, data mining,
text analytics, and data collection. Like SAS can also retrieve data
from different operating systems to perform statistical analyses,
reports, and graphics.

**R** is a language and environment for statistical computing. Its suite
of software facilities are used for data manipulation, calculation and
graphic reporting. R has the advantage to allow users to add new
programing functions.

### Reporting systems

**TIBCO Jaspersoft** is an open source commercial software used in
conjunction with other open source infrastructure like MySQL and JBoss
to retrieve data, and develop reports (Swenson\_2002). The JasperReports
provides resports and analytics that can be embedded into a web or
mobile application in a variety of formats and in real-time.

(Jaspersoft).

**Shiny by RStudio** is a web application framework for R that
transforms analyses into interactive web applications (Shiny). The
application allows the manipulation of the data by sorting, filtering,
and by empowering the user to customize their analysis. At IFAR, Shiny
is used to display different project consort and compliance reports in
real time.

**JIRA** is an Atlassian software development tool used by agile teams
to plan, track, release and report Issue tracking / tasks ticketing
system.

**Google Docs** is a web-based application used to create, edit and
store documents and spreadsheets. Is part of a package offered by and
associated with **Google Apps for Business** and is compatible with most
word processor applications and presentation software (Google\_Docs).

**Atlassian Confluence** is a team collaboration software and enterprise
wiki tool. It is used to create, organize, and discuss the contents of
projects and/or knowledge base of different IFAR centers. The advantage
of Confluence is that documents are edited in real time.
